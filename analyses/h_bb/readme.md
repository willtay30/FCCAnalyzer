# Purpose

This project is to determine the cross section and cross sectional uncertainty on the HZ decay, created through Higgs Strahlung of an electron and positron interaction. This project takes data from this process simulated using proposed Idea detector at the Future Circular Collider (FCC).  

We use simulation data from MIT to form individual root files, which are merged together for easier processing. This merged root file can be plotted and the cross section can be determined using a jupyter notebook script.

We can also use COMBINE, a CMS statistical tool, to analyze the root file instead of the notebook. To do this, we must generate datacards, run COMBINE, and optionally plot the results.

We detail each step below.

# Generating Individual Root Files

Root files for the processes H->bb, H->cc, and H->ss can be generated by using the scripts h_bb.py, h_cc_orthog.py, and h_ss.py.  

These files take the data specified and, for each process, apply several cuts to try to filter out background processes. The histogram of these cuts, as well as histograms on other properties, are then saved into a root file at the output directory. This results in root files for every subprocess being stored in the output directory.  

These files are run using the following command, after sourcing using jsetup.sh:
```shell
fccanalysis run h_bb.py
```

# Merging Root Files

The individual root files are merged together using the script rootmerge.py. This one root file contains all the histograms from each individual root files, stored inside tdirectories labeled based on the process.  

Make sure you look at the script and change the paths/flavour depending on your analysis.  

This script is run by using the following command, after sourcing using jsetup.sh:
```shell
python rootmerge.py
```
This produces a merged rootfile in the directory of choice.


# Plotting & Analysis

This merged root file can be used for plotting and analysis through the jupyter notebook script h_bb.ipynb.

To run, use whatever kernel software to open the script, making sure to change the the paths/flavour.  

Currently, only certain parts of the notebook are guaranteed to work, so keep that in mind when running. These parts include graphs of the cutflow histograms and the script for calculating the cross section.

# Combine

We use COMBINE for a more accurate evaluation of the percent uncertainty in the cross section. There are several steps to generate an output.

## Step 1

First we need to modify the root file to make processing easier, whcih is done using the obs_maker.py script. The output of this script will need to be saved as it is referred to in Step 2. Make sure to update the relevant parameters (root file, maxnumcuts, etc.).  

To run, use the following command with jsetup.sh sourcing:
```shell
python obs_maker.py > output.txt
```

## Step 2

Next, we need to take the root file and generate a datacard that can be using for the input for COMBINE. This is done by running cardmaker.py.  

**Cardmaker.py needs a lot of parameters to be changed for each subprocess! Read the file for more Information!**  

After updating the parameters, run the file using both COMBINE sourcing and jsetup.sh sourcing (in that order).
```shell
python cardwriter.py
```

This should create the datacard in the daracards directory. This also copies the rootfile into that directory, which is needed for the next step.

## Step 2.5

One may be running a process that involves combining multiple datacards first. To do so, first generate each individual datacard using Step 2 (changing the necessary parameters). Then find the location of the combineCards.py script in the COMBINE directory and run with the arguments being each individual datacard and piping the output into the combined datacard.  

Here is an example, this must be run using both the COMBINE sourcing and jsetup.sh sourcing (in that order):
```shell
python /home/submit/aniketkg/FCCAnalyzer/HiggsAnalysis/CombinedLimit/scripts/combineCards.py [datacards] > [output_datacard]
```

## Step 3

Next, COMBINE needs to be run on the actual datacard. For most processes, we use MultDimFit to fit to the output, but for others (ones where the number of signal events is extremely low) we use AsymptoticLimits.  

To run MultDimFit, use the following command sourcing **only** the COMBINE sourcing:
```shell
combine -M MultiDimFit --rMin 0 --rMax 2 --algo grid --points 50 -t -1 --freezeParameters allConstrainedNuisances -n [output_name] --expectSignal=1 -d datacards/[datacard]
```
This creates a root file with a name modified by the -n parameter using the datacard specified by -d, which will be used in Step 4. The rMin, rMax, and points parameters may be changed if one wants to do a wider, more detailed fit. ExpectSignal will set the minimum to be at r=1 and -t -1 allows the use of Asimov datasets. For more questions, consult the COMBINE documentation.  

For AsymptoticLimits, run:
```shell
combine -t -1 -n [output_name] -d datacard/[datacard] > output.txt
```
This stored the output in the text file, with no further processing needed. One can see the value for each execution limit using a 95% confidence level in a table at the bottom.

## Step 4

If running with MultDimFit, the result can be plotted in a nice way. You must locate the plot1DScan.py script in the COMBINE directory.  

Then run the following command, sourcing both the COMBINE sourcing and jsetup.sh sourcing (in that order):
```shell
python /home/submit/aniketkg/FCCAnalyzer/HiggsAnalysis/CombinedLimit/scripts/plot1DScan.py [root output from Step 3] -o [graph location] -l [graph title]
```
This should create a graph with the title provided at the specified location. One can then see the percent cross section uncertainty as the 1 sigma difference on the graph, which is labeled in the top right.